{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756907b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:33.608356Z",
     "iopub.status.busy": "2025-04-25T16:50:33.608114Z",
     "iopub.status.idle": "2025-04-25T16:50:36.438755Z",
     "shell.execute_reply": "2025-04-25T16:50:36.437817Z"
    },
    "papermill": {
     "duration": 2.835727,
     "end_time": "2025-04-25T16:50:36.440337",
     "exception": false,
     "start_time": "2025-04-25T16:50:33.604610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a47ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:36.447036Z",
     "iopub.status.busy": "2025-04-25T16:50:36.446161Z",
     "iopub.status.idle": "2025-04-25T16:50:36.486649Z",
     "shell.execute_reply": "2025-04-25T16:50:36.485675Z"
    },
    "papermill": {
     "duration": 0.044761,
     "end_time": "2025-04-25T16:50:36.487943",
     "exception": false,
     "start_time": "2025-04-25T16:50:36.443182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 945 records from JSON array.\n",
      "Loaded 945 mock transactions.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to your IF results\n",
    "res_path = \"/kaggle/input/isolation-forest-results-and-testing-datasets/blockchain_anomaly_results_encoded.json\"\n",
    "\n",
    "# Try reading as a single JSON array\n",
    "try:\n",
    "    with open(res_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    res_df = pd.DataFrame(data)\n",
    "    print(f\"Loaded {len(res_df)} records from JSON array.\")\n",
    "except ValueError:\n",
    "    # Fallback to line-by-line (NDJSON)\n",
    "    print(\"JSON array load failed; falling back to line-by-line parsing.\")\n",
    "    records = []\n",
    "    with open(res_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            records.append(json.loads(line))\n",
    "    res_df = pd.DataFrame(records)\n",
    "    print(f\"Loaded {len(res_df)} records from NDJSON.\")\n",
    "\n",
    "# Now do the same for your mock transactions if needed:\n",
    "test_path = \"/kaggle/input/isolation-forest-results-and-testing-datasets/mock_blockchain_transactions_large.json\"\n",
    "\n",
    "# Assuming mock file *is* an array of objects, you can just do:\n",
    "with open(test_path, \"r\") as f:\n",
    "    mock_data = json.load(f)\n",
    "test_df = pd.DataFrame(mock_data)\n",
    "print(f\"Loaded {len(test_df)} mock transactions.\")\n",
    "\n",
    "# …and then proceed with the merge, filter, feature extraction, and predictions as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0700e9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:36.494153Z",
     "iopub.status.busy": "2025-04-25T16:50:36.493458Z",
     "iopub.status.idle": "2025-04-25T16:50:36.515884Z",
     "shell.execute_reply": "2025-04-25T16:50:36.514992Z"
    },
    "papermill": {
     "duration": 0.026718,
     "end_time": "2025-04-25T16:50:36.517081",
     "exception": false,
     "start_time": "2025-04-25T16:50:36.490363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Merge on tx_hash to align IF prediction with ground truth\n",
    "merged = pd.merge(\n",
    "    res_df, test_df,\n",
    "    left_on=\"tx_hash\", right_on=\"tx_hash\",\n",
    "    suffixes=(\"_if\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fc6371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:36.522582Z",
     "iopub.status.busy": "2025-04-25T16:50:36.522318Z",
     "iopub.status.idle": "2025-04-25T16:50:36.532347Z",
     "shell.execute_reply": "2025-04-25T16:50:36.531431Z"
    },
    "papermill": {
     "duration": 0.014084,
     "end_time": "2025-04-25T16:50:36.533546",
     "exception": false,
     "start_time": "2025-04-25T16:50:36.519462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 850 IF-authentic transactions\n"
     ]
    }
   ],
   "source": [
    "# 3. Merge and filter for all IF-“authentic” predictions\n",
    "merged = pd.merge(res_df, test_df, on=\"tx_hash\", suffixes=(\"_if\", \"\"))\n",
    "auth_df = merged[merged[\"anomaly\"] == \"authentic\"].copy()\n",
    "print(f\"Running on {len(auth_df)} IF-authentic transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41324d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:36.538810Z",
     "iopub.status.busy": "2025-04-25T16:50:36.538547Z",
     "iopub.status.idle": "2025-04-25T16:50:36.552883Z",
     "shell.execute_reply": "2025-04-25T16:50:36.552041Z"
    },
    "papermill": {
     "duration": 0.018397,
     "end_time": "2025-04-25T16:50:36.554228",
     "exception": false,
     "start_time": "2025-04-25T16:50:36.535831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Build the feature DataFrame\n",
    "auth_df[\"TimeStamp\"] = pd.to_datetime(auth_df[\"timestamp\"], unit=\"s\")\n",
    "for fld in [\"hour\",\"day\",\"month\",\"year\"]:\n",
    "    auth_df[fld] = getattr(auth_df[\"TimeStamp\"].dt, fld)\n",
    "\n",
    "X_auth = auth_df.rename(columns={\n",
    "    \"block_number\": \"BlockHeight\",\n",
    "    \"value\":        \"Value\",\n",
    "    \"from\":         \"From\",\n",
    "    \"to\":           \"To\"\n",
    "})[[\n",
    "    \"BlockHeight\",\"Value\",\n",
    "    \"hour\",\"day\",\"month\",\"year\",\n",
    "    \"From\",\"To\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ca09e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:36.559379Z",
     "iopub.status.busy": "2025-04-25T16:50:36.559152Z",
     "iopub.status.idle": "2025-04-25T16:50:45.534871Z",
     "shell.execute_reply": "2025-04-25T16:50:45.534050Z"
    },
    "papermill": {
     "duration": 8.979838,
     "end_time": "2025-04-25T16:50:45.536247",
     "exception": false,
     "start_time": "2025-04-25T16:50:36.556409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to test: ['RF+XGB', 'MLP', 'RF+MLP', 'XGB', 'RF+MLP+XGB', 'MLP+XGB', 'RF']\n"
     ]
    }
   ],
   "source": [
    "# 5. Load your saved pipelines from the Kaggle input dir\n",
    "model_dir = \"/kaggle/input/comp517_models/scikitlearn/default/1\"\n",
    "pipelines = {}\n",
    "for fname in os.listdir(model_dir):\n",
    "    if fname.startswith(\"pipeline_\") and fname.endswith(\".pkl\"):\n",
    "        name = fname.replace(\"pipeline_\",\"\").replace(\".pkl\",\"\").replace(\"_\",\"+\")\n",
    "        with open(os.path.join(model_dir, fname),\"rb\") as f:\n",
    "            pipelines[name] = pickle.load(f)\n",
    "\n",
    "print(\"Models to test:\", list(pipelines.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7e5c6b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:45.544105Z",
     "iopub.status.busy": "2025-04-25T16:50:45.543451Z",
     "iopub.status.idle": "2025-04-25T16:50:46.361579Z",
     "shell.execute_reply": "2025-04-25T16:50:46.360692Z"
    },
    "papermill": {
     "duration": 0.823586,
     "end_time": "2025-04-25T16:50:46.362851",
     "exception": false,
     "start_time": "2025-04-25T16:50:45.539265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF+XGB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.70      1.00      0.83       599\n",
      "    Error(1)       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.70       850\n",
      "   macro avg       0.35      0.50      0.41       850\n",
      "weighted avg       0.50      0.70      0.58       850\n",
      "\n",
      "Accuracy: 70.47% (599/850)\n",
      "\n",
      "=== MLP ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.00      0.00      0.00       599\n",
      "    Error(1)       0.30      1.00      0.46       251\n",
      "\n",
      "    accuracy                           0.30       850\n",
      "   macro avg       0.15      0.50      0.23       850\n",
      "weighted avg       0.09      0.30      0.13       850\n",
      "\n",
      "Accuracy: 29.53% (251/850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF+MLP ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.00      0.00      0.00       599\n",
      "    Error(1)       0.30      1.00      0.46       251\n",
      "\n",
      "    accuracy                           0.30       850\n",
      "   macro avg       0.15      0.50      0.23       850\n",
      "weighted avg       0.09      0.30      0.13       850\n",
      "\n",
      "Accuracy: 29.53% (251/850)\n",
      "\n",
      "=== XGB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.70      1.00      0.83       599\n",
      "    Error(1)       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.70       850\n",
      "   macro avg       0.35      0.50      0.41       850\n",
      "weighted avg       0.50      0.70      0.58       850\n",
      "\n",
      "Accuracy: 70.47% (599/850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF+MLP+XGB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.70      1.00      0.83       599\n",
      "    Error(1)       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.70       850\n",
      "   macro avg       0.35      0.50      0.41       850\n",
      "weighted avg       0.50      0.70      0.58       850\n",
      "\n",
      "Accuracy: 70.47% (599/850)\n",
      "\n",
      "=== MLP+XGB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.69      0.92      0.79       599\n",
      "    Error(1)       0.02      0.00      0.01       251\n",
      "\n",
      "    accuracy                           0.65       850\n",
      "   macro avg       0.35      0.46      0.40       850\n",
      "weighted avg       0.49      0.65      0.56       850\n",
      "\n",
      "Accuracy: 65.06% (553/850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Valid(0)       0.70      1.00      0.83       599\n",
      "    Error(1)       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.70       850\n",
      "   macro avg       0.35      0.50      0.41       850\n",
      "weighted avg       0.50      0.70      0.58       850\n",
      "\n",
      "Accuracy: 70.47% (599/850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict, evaluate, and summarize with correctness\n",
    "# Ground‐truth: 0 if type==\"authentic\", else 1\n",
    "ground_truth = (auth_df[\"type\"] != \"authentic\").astype(int).values\n",
    "\n",
    "summary = []\n",
    "for name, pipe in pipelines.items():\n",
    "    preds = pipe.predict(X_auth)\n",
    "    \n",
    "    # counts\n",
    "    valid_count = int((preds == 0).sum())\n",
    "    error_count = int((preds == 1).sum())\n",
    "    \n",
    "    # correctness\n",
    "    correct = int((preds == ground_truth).sum())\n",
    "    accuracy = correct / len(preds)\n",
    "    \n",
    "    # print full classification report\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(ground_truth, preds, target_names=[\"Valid(0)\",\"Error(1)\"]))\n",
    "    print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(preds)})\")\n",
    "    \n",
    "    summary.append({\n",
    "        \"Model\":     name,\n",
    "        \"Valid (0)\": valid_count,\n",
    "        \"Error (1)\": error_count,\n",
    "        \"Correct\":   correct,\n",
    "        \"Total\":     len(preds),\n",
    "        \"Accuracy\":  accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e93e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:46.369758Z",
     "iopub.status.busy": "2025-04-25T16:50:46.369520Z",
     "iopub.status.idle": "2025-04-25T16:50:46.385094Z",
     "shell.execute_reply": "2025-04-25T16:50:46.384415Z"
    },
    "papermill": {
     "duration": 0.020081,
     "end_time": "2025-04-25T16:50:46.386143",
     "exception": false,
     "start_time": "2025-04-25T16:50:46.366062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Summary:\n",
      "        Model  Valid (0)  Error (1)  Correct  Total  Accuracy\n",
      "0      RF+XGB        850          0      599    850  0.704706\n",
      "1         MLP          0        850      251    850  0.295294\n",
      "2      RF+MLP          0        850      251    850  0.295294\n",
      "3         XGB        850          0      599    850  0.704706\n",
      "4  RF+MLP+XGB        850          0      599    850  0.704706\n",
      "5     MLP+XGB        802         48      553    850  0.650588\n",
      "6          RF        850          0      599    850  0.704706\n",
      "\n",
      "Saved detailed summary to authentic_prediction_summary_with_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "# 7. Tabulate & save summary\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\nOverall Summary:\")\n",
    "print(summary_df)\n",
    "\n",
    "summary_df.to_csv(\"authentic_prediction_summary_with_accuracy.csv\", index=False)\n",
    "print(\"\\nSaved detailed summary to authentic_prediction_summary_with_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9bc5a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:46.392452Z",
     "iopub.status.busy": "2025-04-25T16:50:46.392265Z",
     "iopub.status.idle": "2025-04-25T16:50:46.406521Z",
     "shell.execute_reply": "2025-04-25T16:50:46.405732Z"
    },
    "papermill": {
     "duration": 0.018658,
     "end_time": "2025-04-25T16:50:46.407613",
     "exception": false,
     "start_time": "2025-04-25T16:50:46.388955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest Accuracy: 694/945 = 73.44%\n",
      "\n",
      "Confusion Matrix (rows=truth, cols=IF prediction):\n",
      "               Pred Auth (0)  Pred Anom (1)\n",
      "True Auth (0)            599              0\n",
      "True Anom (1)            251             95 \n",
      "\n",
      "Classification Report for Isolation Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Authentic (0)       0.70      1.00      0.83       599\n",
      "  Anomaly (1)       1.00      0.27      0.43       346\n",
      "\n",
      "     accuracy                           0.73       945\n",
      "    macro avg       0.85      0.64      0.63       945\n",
      " weighted avg       0.81      0.73      0.68       945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# — After merging res_df and test_df into `merged` —\n",
    "\n",
    "# 1. Build binary labels:\n",
    "#    0 = authentic; 1 = anomaly\n",
    "y_true = (merged[\"type\"]    != \"authentic\").astype(int).values\n",
    "y_if   = (merged[\"anomaly\"] != \"authentic\").astype(int).values\n",
    "\n",
    "# 2. Print overall accuracy\n",
    "total   = len(y_true)\n",
    "correct = (y_true == y_if).sum()\n",
    "print(f\"Isolation Forest Accuracy: {correct}/{total} = {correct/total:.2%}\\n\")\n",
    "\n",
    "# 3. Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_if)\n",
    "print(\"Confusion Matrix (rows=truth, cols=IF prediction):\")\n",
    "print(pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"True Auth (0)\", \"True Anom (1)\"],\n",
    "    columns=[\"Pred Auth (0)\", \"Pred Anom (1)\"]\n",
    "), \"\\n\")\n",
    "\n",
    "# 4. Detailed classification report\n",
    "print(\"Classification Report for Isolation Forest:\")\n",
    "print(classification_report(y_true, y_if, target_names=[\"Authentic (0)\", \"Anomaly (1)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c1bff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:50:46.414254Z",
     "iopub.status.busy": "2025-04-25T16:50:46.413753Z",
     "iopub.status.idle": "2025-04-25T16:50:46.428911Z",
     "shell.execute_reply": "2025-04-25T16:50:46.428089Z"
    },
    "papermill": {
     "duration": 0.019623,
     "end_time": "2025-04-25T16:50:46.430089",
     "exception": false,
     "start_time": "2025-04-25T16:50:46.410466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IF-authentic predictions: 850\n",
      "\n",
      "Confusion Matrix on IF-authentic subset:\n",
      "                    Pred Authentic (0)  Pred Anomaly (1)\n",
      "True Authentic (0)                 599                 0\n",
      "True Anomaly (1)                   251                 0\n",
      "\n",
      "Accuracy on IF-authentic subset: 70.47% (599/850)\n",
      "\n",
      "Classification Report (treating IF-authentic as pred=0):\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Authentic (true=0)       0.70      1.00      0.83       599\n",
      "  Anomaly (true=1)       0.00      0.00      0.00       251\n",
      "\n",
      "          accuracy                           0.70       850\n",
      "         macro avg       0.35      0.50      0.41       850\n",
      "      weighted avg       0.50      0.70      0.58       850\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# — assume you have already merged res_df and test_df into `merged` —\n",
    "\n",
    "# 1. Filter to the IF-“authentic” subset\n",
    "auth_if = merged[merged[\"anomaly\"] == \"authentic\"].copy()\n",
    "print(f\"Total IF-authentic predictions: {len(auth_if)}\")\n",
    "\n",
    "# 2. Build binary labels:\n",
    "#    y_true: 0 if truly authentic, 1 if actually an anomaly\n",
    "y_true_sub = (auth_if[\"type\"] != \"authentic\").astype(int).values\n",
    "#    y_pred: 0 for IF-authentic (since anomaly==\"authentic\"), 1 otherwise\n",
    "y_pred_sub = (auth_if[\"anomaly\"] != \"authentic\").astype(int).values  # will be all zeros\n",
    "\n",
    "# 3. Confusion matrix (rows=true, cols=pred)\n",
    "cm = confusion_matrix(y_true_sub, y_pred_sub, labels=[0,1])\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=[\"True Authentic (0)\",\"True Anomaly (1)\"],\n",
    "                     columns=[\"Pred Authentic (0)\",\"Pred Anomaly (1)\"])\n",
    "print(\"\\nConfusion Matrix on IF-authentic subset:\")\n",
    "print(cm_df)\n",
    "\n",
    "# 4. Accuracy on that subset\n",
    "accuracy = (y_true_sub == y_pred_sub).mean()\n",
    "print(f\"\\nAccuracy on IF-authentic subset: {accuracy:.2%} ({(y_true_sub==y_pred_sub).sum()}/{len(y_true_sub)})\")\n",
    "\n",
    "# 5. Classification report\n",
    "print(\"\\nClassification Report (treating IF-authentic as pred=0):\")\n",
    "print(classification_report(y_true_sub, y_pred_sub,\n",
    "      target_names=[\"Authentic (true=0)\",\"Anomaly (true=1)\"]))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7251618,
     "sourceId": 11565771,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 315778,
     "modelInstanceId": 295168,
     "sourceId": 353835,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.75485,
   "end_time": "2025-04-25T16:50:47.050802",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T16:50:29.295952",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
